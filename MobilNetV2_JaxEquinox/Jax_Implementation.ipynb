{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax Implementation of MobileNetV2\n",
    "The following is a jax and equinox implementation of the MobileNetV2 architecture\n",
    "\n",
    "The implementation is broken up into its individual (modulo stride) layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Tuple, Optional, Union, Sequence\n",
    "from jaxtyping import Array, Float, Int, PyTree\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "import equinox as eqx\n",
    "\n",
    "import optax as opt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2\n",
    "\n",
    "The following is the full implementation of the MobileNetV2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Depthwise Separable Convolution Layer\n",
    "class DepthwiseSeparableConv(eqx.Module):\n",
    "    depthwise: eqx.nn.Conv2d\n",
    "    pointwise: eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, key):\n",
    "        dw_key, pw_key = jax.random.split(key)\n",
    "        self.depthwise = eqx.nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=in_channels, \n",
    "            kernel_size=(3, 3), \n",
    "            stride=stride, \n",
    "            padding=1, \n",
    "            groups=in_channels,\n",
    "            key=dw_key\n",
    "        )\n",
    "        self.pointwise = eqx.nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=(3, 3), \n",
    "            key=pw_key\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [reference](https://github.com/DarshanDeshpande/jax-models/blob/main/jax_models/layers/depthwise_separable_conv.py)\n",
    "class DepthwiseConv2D(eqx.Module):\n",
    "    in_channels: int = eqx.field(static=True)\n",
    "    out_channels: int = eqx.field(static=True)\n",
    "    kernel_size: Union[int, Sequence[int]] = eqx.field(static=True)\n",
    "    stride: Union[int, Sequence[int]] = eqx.field(static=True)\n",
    "    padding: str = eqx.field(static=True)\n",
    "    depth_multiplier: int = eqx.field(static=True)\n",
    "    use_bias: bool = eqx.field(static=True)\n",
    "    groups: int = eqx.field(static=True)\n",
    "    key: Any = eqx.field(static=True)\n",
    "\n",
    "    kernel: Array\n",
    "    bias: Array\n",
    "\n",
    "    def __init__(self, in_channels: int, depth_multiplier: int, kernel_size: Tuple[int, int], stride: Tuple[int, int], padding: str, use_bias: bool, key: jr.PRNGKey):\n",
    "        self.in_channels = in_channels\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.out_channels = in_channels * depth_multiplier\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding.upper()\n",
    "        self.use_bias = False\n",
    "        self.groups = in_channels\n",
    "        self.key = key\n",
    "\n",
    "        # if self.padding.lower() is not \"valid\" and self.padding is not \"same\":\n",
    "        #     raise ValueError(\"Padding must be either 'valid' or 'same'\")\n",
    "\n",
    "        self.kernel = jr.uniform(\n",
    "            key,\n",
    "            shape = (1, self.depth_multiplier * self.in_channels, *self.kernel_size)\n",
    "        )\n",
    "\n",
    "        if use_bias:\n",
    "            self.bias = jr.normal(key, shape=(in_channels * depth_multiplier,))\n",
    "            self.use_bias = True\n",
    "        else:\n",
    "            self.bias = jnp.zeros((in_channels * depth_multiplier,))\n",
    "\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        # x = x.reshape((x.shape[0], 1, *x.shape[1:]))\n",
    "        x = jnp.expand_dims(x, axis=0)\n",
    "        x = jax.lax.conv_general_dilated(\n",
    "            lhs=x,\n",
    "            rhs=self.kernel,\n",
    "            window_strides=self.stride,\n",
    "            padding=self.padding.upper(),\n",
    "            lhs_dilation=(1,) * len(self.kernel_size),\n",
    "            rhs_dilation=(1,) * len(self.kernel_size),\n",
    "            dimension_numbers=(\"NCHW\", \"OIHW\", \"NCHW\"),\n",
    "            # feature_group_count=x.shape[-1]\n",
    "            # feature_group_count=1\n",
    "        )\n",
    "        x = x.squeeze(axis=0)\n",
    "        if self.use_bias:\n",
    "            x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an inverted residual block [reference](https://github.com/keras-team/keras/blob/v3.3.3/keras/src/applications/mobilenet_v2.py#L398)\n",
    "class InvertedResidualBlock(eqx.Module):\n",
    "    # static fields get ignored durign training\n",
    "    in_channels:  int   = eqx.field(static=True)\n",
    "    expansion:    int   = eqx.field(static=True)\n",
    "    stride:       int   = eqx.field(static=True)\n",
    "    alpha:        float = eqx.field(static=True)\n",
    "    filters:      int   = eqx.field(static=True)\n",
    "    pw_filters:   int   = eqx.field(static=True)\n",
    "    block_id:     int   = eqx.field(static=True)\n",
    "\n",
    "    layers: List[Any]\n",
    "    \n",
    "\n",
    "    def _make_divisible(self, v, divisor, min_value=None):\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "    def __init__(self, in_channels: int, expansion: int, stride: int, alpha: float, filters: int, block_id: int, key: jr.PRNGKey, BATCH_SIZE: int):\n",
    "        self.in_channels = in_channels\n",
    "        self.expansion = expansion\n",
    "        self.stride = stride\n",
    "        self.alpha = alpha\n",
    "        self.filters = filters\n",
    "        self.block_id = block_id\n",
    "\n",
    "        pointwise_filters = int(filters * alpha)\n",
    "        # ensure that the number of filters on the last 1x1 convolution is a multiple of 8\n",
    "        pointwise_filters = self._make_divisible(pointwise_filters, 8)\n",
    "        self.pw_filters = pointwise_filters\n",
    "\n",
    "        # Define the key for the block\n",
    "        key, conv_key = jr.split(key)\n",
    "        self.layers = []\n",
    "\n",
    "        # Define the layers of the block\n",
    "        if block_id:\n",
    "            # Expand with a pointwise 1x1 convolution\n",
    "            self.layers.extend([\n",
    "                eqx.nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=in_channels * expansion,\n",
    "                    kernel_size=(1, 1),\n",
    "                    use_bias=False,\n",
    "                    key=conv_key\n",
    "                ),\n",
    "                eqx.nn.BatchNorm(\n",
    "                    BATCH_SIZE,\n",
    "                    axis_name='batch',\n",
    "                    eps=1e-3,\n",
    "                    momentum=0.99\n",
    "                ),\n",
    "                jax.nn.relu6\n",
    "            ])\n",
    "        \n",
    "        self.layers.extend([\n",
    "            DepthwiseConv2D(\n",
    "                in_channels=in_channels * expansion,\n",
    "                depth_multiplier=1,\n",
    "                kernel_size=(1, 1),\n",
    "                stride=(stride, stride),\n",
    "                padding=\"valid\",\n",
    "                key=conv_key,\n",
    "                use_bias=False\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                BATCH_SIZE,\n",
    "                axis_name='batch',\n",
    "                eps=1e-3,\n",
    "                momentum=0.99\n",
    "            ),\n",
    "            jax.nn.relu6\n",
    "        ])\n",
    "\n",
    "        # pointwise 1x1 conv\n",
    "        self.layers.extend([\n",
    "            eqx.nn.Conv2d(\n",
    "                in_channels=in_channels * expansion,\n",
    "                out_channels=pointwise_filters,\n",
    "                kernel_size=(1, 1),\n",
    "                use_bias=False,\n",
    "                key=conv_key\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                BATCH_SIZE,\n",
    "                axis_name='batch',\n",
    "                eps=1e-3,\n",
    "                momentum=0.99\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, x, state):\n",
    "        input = x\n",
    "\n",
    "        lc = 0\n",
    "        \n",
    "        if self.block_id:\n",
    "            x = self.layers[0](x)\n",
    "            x, state = self.layers[1](x, state)\n",
    "            x = self.layers[2](x)\n",
    "            lc = 3\n",
    "        if self.stride == 2:\n",
    "            x = jnp.pad(x, 1, mode='constant', constant_values=0)\n",
    "\n",
    "        for _, layer in enumerate(self.layers[lc:]):\n",
    "            if issubclass(type(layer), eqx.nn.StatefulLayer):\n",
    "                x, state = layer(x, state)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        if self.in_channels == self.pw_filters and self.stride == 1:\n",
    "            x = x + input\n",
    "\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Bottleneck Block\n",
    "class Bottleneck(eqx.Module):\n",
    "    _stride: int = eqx.field(static=True)\n",
    "\n",
    "    conv1: eqx.nn.Conv2d\n",
    "    depthwise_conv: DepthwiseSeparableConv\n",
    "    conv3: eqx.nn.Conv2d\n",
    "    use_residual: bool\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio, use_residual, key: jr.PRNGKey):\n",
    "        self._stride=stride\n",
    "        keys = jr.split(key, 3)\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.conv1 = eqx.nn.Conv2d(in_channels, hidden_dim, kernel_size=(1, 1), key=keys[0])\n",
    "        self.depthwise_conv = [DepthwiseSeparableConv(hidden_dim, hidden_dim, stride=1, key=keys[1]),\n",
    "                               DepthwiseSeparableConv(hidden_dim, hidden_dim, stride=2, key=keys[1])]\n",
    "        self.conv3 = eqx.nn.Conv2d(hidden_dim, out_channels, kernel_size=(1, 1), key=keys[2])\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "    def __call__(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        if self._stride == 1:\n",
    "            x = self.depthwise_conv[0](x)\n",
    "            x = jax.nn.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            return x + residual\n",
    "        else:\n",
    "            x = self.depthwise_conv[1](x)\n",
    "            x = jax.nn.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MobileNetV2\n",
    "class MobileNetV2(eqx.Module):\n",
    "    in_channels: int = eqx.field(static=True)\n",
    "    \n",
    "    first_conv: eqx.nn.Conv2d\n",
    "    bottlenecks: list\n",
    "    last_conv: eqx.nn.Conv2d\n",
    "    pool: eqx.nn.AvgPool2d\n",
    "    classifier: eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self, in_channels, num_classes, key):\n",
    "        keys = jax.random.split(key, 10)\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.first_conv = eqx.nn.Conv2d(in_channels, 32, kernel_size=(3, 3), stride=2, padding=1, key=keys[0])\n",
    "\n",
    "        # Bottleneck blocks configuration\n",
    "        bottleneck_configs = [\n",
    "            # (in_channels, out_channels, stride, expand_ratio, n_repeats)\n",
    "            (32, 16, 1, 1, 1),   # First block, no expansion, no repetition\n",
    "            (16, 24, 2, 6, 2),   # Second block, 2x stride, 2 repetitions\n",
    "            (24, 32, 2, 6, 3),   # Third block, 2x stride, 3 repetitions\n",
    "            (32, 64, 2, 6, 4),   # Fourth block, 2x stride, 4 repetitions\n",
    "            (64, 96, 1, 6, 3),   # Fifth block, stride 1, 3 repetitions\n",
    "            (96, 160, 2, 6, 3),  # Sixth block, 2x stride, 3 repetitions\n",
    "            (160, 320, 1, 6, 1), # Seventh block, stride 1, no repetition\n",
    "        ]\n",
    "\n",
    "        self.bottlenecks = []\n",
    "        current_key = keys[1]\n",
    "\n",
    "        for config in bottleneck_configs:\n",
    "            in_channels, out_channels, stride, expand_ratio, n_repeats = config\n",
    "\n",
    "            # Add the first block in the stage with the specified stride\n",
    "            self.bottlenecks.append(\n",
    "                Bottleneck(in_channels, out_channels, stride, expand_ratio, use_residual=(stride == 1), key=current_key)\n",
    "            )\n",
    "            current_key = jax.random.split(current_key, 1)[0]\n",
    "\n",
    "            # Add the remaining blocks with stride = 1\n",
    "            for i in range(n_repeats - 1):\n",
    "                self.bottlenecks.append(\n",
    "                    Bottleneck(out_channels, out_channels, stride=1, expand_ratio=expand_ratio, use_residual=True, key=current_key)\n",
    "                )\n",
    "                current_key = jax.random.split(current_key, 1)[0]\n",
    "\n",
    "        self.last_conv = eqx.nn.Conv2d(24, 1280, kernel_size=(1, 1), key=keys[2])\n",
    "        self.pool = eqx.nn.AvgPool2d(kernel_size=(7, 7))\n",
    "        self.classifier = eqx.nn.Conv2d(1280, num_classes, kernel_size=(1,1),key=keys[3])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = jax.nn.relu(x)\n",
    "\n",
    "        for bottleneck in self.bottlenecks:\n",
    "            x = bottleneck(x)\n",
    "\n",
    "        x = self.last_conv(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = jnp.mean(x, axis=(1, 2))  # Global average pooling\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2 model based on the Keras implementation\n",
    "class MobileNetV2_K(eqx.Module):\n",
    "    layers: List[Any]\n",
    "\n",
    "    def _make_divisible(self, v, divisor, min_value=None):\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "    def __init__(self,\n",
    "        in_channels: int = 3,\n",
    "        alpha: float = 1.0,\n",
    "        include_top: bool = True,\n",
    "        num_classes: int = 1000,\n",
    "        classifier_activation: str = 'softmax',\n",
    "        pooling: Optional[str] = None,\n",
    "        key: jr.PRNGKey = jr.PRNGKey(0),\n",
    "        BATCH_SIZE: int = 32\n",
    "    ):\n",
    "        key, conv_key = jr.split(key)\n",
    "        \n",
    "        first_block_filters = self._make_divisible(32 * alpha, 8)\n",
    "        if alpha > 1.0:\n",
    "            last_block_filters = self._make_divisible(1280 * alpha, 8)\n",
    "        else:\n",
    "            last_block_filters = 1280\n",
    "\n",
    "        self.layers = [\n",
    "            eqx.nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=first_block_filters,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(2, 2),\n",
    "                # padding=(15, 15), # equivalent to TF 'same' padding\n",
    "                use_bias=False,\n",
    "                key=conv_key\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                input_size=first_block_filters,\n",
    "                eps=1e-3,\n",
    "                momentum=0.99,\n",
    "                axis_name=\"batch\"\n",
    "            ),\n",
    "            jax.nn.relu6,\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=first_block_filters,\n",
    "                expansion=1,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=16,\n",
    "                block_id=0,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=16,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=24,\n",
    "                block_id=1,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=24,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=24,\n",
    "                block_id=2,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=24,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=32,\n",
    "                block_id=3,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=32,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=32,\n",
    "                block_id=4,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=32,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=32,\n",
    "                block_id=5,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=32,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=6,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=7,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=8,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=9,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=96,\n",
    "                block_id=10,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=96,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=96,\n",
    "                block_id=11,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=96,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=96,\n",
    "                block_id=12,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=96,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=160,\n",
    "                block_id=13,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=160,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=160,\n",
    "                block_id=14,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=160,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=160,\n",
    "                block_id=15,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=160,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=320,\n",
    "                block_id=16,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            eqx.nn.Conv2d(\n",
    "                in_channels=320,\n",
    "                out_channels=last_block_filters,\n",
    "                kernel_size=(1, 1),\n",
    "                use_bias=False,\n",
    "                key=conv_key\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                input_size=BATCH_SIZE,\n",
    "                eps=1e-3,\n",
    "                momentum=0.999,\n",
    "                axis_name=\"batch\"\n",
    "            ),\n",
    "            jax.nn.relu6\n",
    "        ]\n",
    "\n",
    "        if include_top:\n",
    "            self.layers.extend([\n",
    "                eqx.nn.AvgPool2d(kernel_size=(7, 7)), # TODO: replace with global average pooling\n",
    "                eqx.nn.Linear(\n",
    "                    in_features=last_block_filters,\n",
    "                    out_features=num_classes,\n",
    "                    key=key\n",
    "                )\n",
    "            ])\n",
    "            if classifier_activation == 'softmax':\n",
    "                self.layers.append(jax.nn.softmax)\n",
    "\n",
    "        else:\n",
    "            if pooling == 'avg':\n",
    "                self.layers.append(eqx.nn.AvgPool2d(kernel_size=(7, 7))) # TODO: replace with global average pooling\n",
    "            elif pooling == 'max':\n",
    "                self.layers.append(eqx.nn.MaxPool2d(kernel_size=(7, 7))) # TODO: replace with global max pooling\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        for layer in self.layers:\n",
    "            if issubclass(type(layer), eqx.nn.StatefulLayer) or isinstance(layer, InvertedResidualBlock):\n",
    "                x, state = layer(x, state)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 300\n",
    "BATCH_SIZE = 32\n",
    "PRINT_EVERY = 30\n",
    "SEED = 42\n",
    "\n",
    "# Key generation\n",
    "key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test with MNIST\n",
    "\n",
    "# Load the MNIST dataset [reference](https://docs.kidger.site/equinox/examples/mnist/#the-dataset)\n",
    "normalise_data = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "# we aren't using a validation set here, but that's easy enough to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 28, 28)\n",
      "(32,)\n",
      "[1 1 1 6 3 6 8 1 9 6 0 4 9 5 3 8 0 6 8 6 5 3 7 8 1 8 8 8 8 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "# Checking our data a bit (by now, everyone knows what the MNIST dataset looks like)\n",
    "dummy_x, dummy_y = next(iter(trainloader))\n",
    "dummy_x = dummy_x.numpy()\n",
    "dummy_y = dummy_y.numpy()\n",
    "print(dummy_x.shape)  # 64x1x28x28\n",
    "print(dummy_y.shape)  # 64\n",
    "print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2_K(\n",
      "  layers=[\n",
      "    Conv2d(\n",
      "      num_spatial_dims=2,\n",
      "      weight=f32[32,1,3,3],\n",
      "      bias=None,\n",
      "      in_channels=1,\n",
      "      out_channels=32,\n",
      "      kernel_size=(3, 3),\n",
      "      stride=(2, 2),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      use_bias=False,\n",
      "      padding_mode='ZEROS'\n",
      "    ),\n",
      "    BatchNorm(\n",
      "      weight=f32[32],\n",
      "      bias=f32[32],\n",
      "      first_time_index=StateIndex(\n",
      "        marker=0,\n",
      "        init=<object object at 0x7f386c3e3cf0>\n",
      "      ),\n",
      "      state_index=StateIndex(marker=1, init=<object object at 0x7f386c3e3cf0>),\n",
      "      axis_name='batch',\n",
      "      inference=False,\n",
      "      input_size=32,\n",
      "      eps=0.001,\n",
      "      channelwise_affine=True,\n",
      "      momentum=0.99\n",
      "    ),\n",
      "    <wrapped function relu6>,\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=1,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=16,\n",
      "      pw_filters=16,\n",
      "      block_id=0,\n",
      "      layers=[\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=32,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=32,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,32,1,1],\n",
      "          bias=f32[32]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=2,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=3,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[16,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=16,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=4,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=5,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=16,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=24,\n",
      "      pw_filters=24,\n",
      "      block_id=1,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,16,1,1],\n",
      "          bias=None,\n",
      "          in_channels=16,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=6,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=7,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=96,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(2, 2),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=96,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,96,1,1],\n",
      "          bias=f32[96]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=8,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=9,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[24,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=24,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=10,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=11,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=24,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=24,\n",
      "      pw_filters=24,\n",
      "      block_id=2,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[144,24,1,1],\n",
      "          bias=None,\n",
      "          in_channels=24,\n",
      "          out_channels=144,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=12,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=13,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=144,\n",
      "          out_channels=144,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=144,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,144,1,1],\n",
      "          bias=f32[144]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=14,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=15,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[24,144,1,1],\n",
      "          bias=None,\n",
      "          in_channels=144,\n",
      "          out_channels=24,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=16,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=17,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=24,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=32,\n",
      "      pw_filters=32,\n",
      "      block_id=3,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[144,24,1,1],\n",
      "          bias=None,\n",
      "          in_channels=24,\n",
      "          out_channels=144,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=18,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=19,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=144,\n",
      "          out_channels=144,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(2, 2),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=144,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,144,1,1],\n",
      "          bias=f32[144]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=20,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=21,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[32,144,1,1],\n",
      "          bias=None,\n",
      "          in_channels=144,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=22,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=23,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=32,\n",
      "      pw_filters=32,\n",
      "      block_id=4,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[192,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=24,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=25,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=192,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=192,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,192,1,1],\n",
      "          bias=f32[192]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=26,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=27,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[32,192,1,1],\n",
      "          bias=None,\n",
      "          in_channels=192,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=28,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=29,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=32,\n",
      "      pw_filters=32,\n",
      "      block_id=5,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[192,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=30,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=31,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=192,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=192,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,192,1,1],\n",
      "          bias=f32[192]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=32,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=33,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[32,192,1,1],\n",
      "          bias=None,\n",
      "          in_channels=192,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=34,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=35,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=6,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[192,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=36,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=37,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=192,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(2, 2),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=192,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,192,1,1],\n",
      "          bias=f32[192]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=38,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=39,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,192,1,1],\n",
      "          bias=None,\n",
      "          in_channels=192,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=40,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=41,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=7,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=42,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=43,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,384,1,1],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=44,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=45,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=46,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=47,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=8,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=48,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=49,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,384,1,1],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=50,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=51,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=52,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=53,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=9,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=54,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=55,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,384,1,1],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=56,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=57,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=58,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=59,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=96,\n",
      "      pw_filters=96,\n",
      "      block_id=10,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=60,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=61,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,384,1,1],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=62,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=63,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=64,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=65,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=96,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=96,\n",
      "      pw_filters=96,\n",
      "      block_id=11,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[576,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=66,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=67,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=576,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=576,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,576,1,1],\n",
      "          bias=f32[576]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=68,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=69,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,576,1,1],\n",
      "          bias=None,\n",
      "          in_channels=576,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=70,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=71,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=96,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=96,\n",
      "      pw_filters=96,\n",
      "      block_id=12,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[576,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=72,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=73,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=576,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=576,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,576,1,1],\n",
      "          bias=f32[576]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=74,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=75,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,576,1,1],\n",
      "          bias=None,\n",
      "          in_channels=576,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=76,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=77,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=96,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=160,\n",
      "      pw_filters=160,\n",
      "      block_id=13,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[576,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=78,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=79,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=576,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(2, 2),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=576,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,576,1,1],\n",
      "          bias=f32[576]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=80,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=81,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[160,576,1,1],\n",
      "          bias=None,\n",
      "          in_channels=576,\n",
      "          out_channels=160,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=82,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=83,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=160,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=160,\n",
      "      pw_filters=160,\n",
      "      block_id=14,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[960,160,1,1],\n",
      "          bias=None,\n",
      "          in_channels=160,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=84,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=85,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=960,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=960,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,960,1,1],\n",
      "          bias=f32[960]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=86,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=87,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[160,960,1,1],\n",
      "          bias=None,\n",
      "          in_channels=960,\n",
      "          out_channels=160,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=88,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=89,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=160,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=160,\n",
      "      pw_filters=160,\n",
      "      block_id=15,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[960,160,1,1],\n",
      "          bias=None,\n",
      "          in_channels=160,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=90,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=91,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=960,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=960,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,960,1,1],\n",
      "          bias=f32[960]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=92,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=93,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[160,960,1,1],\n",
      "          bias=None,\n",
      "          in_channels=960,\n",
      "          out_channels=160,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=94,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=95,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=160,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=320,\n",
      "      pw_filters=320,\n",
      "      block_id=16,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[960,160,1,1],\n",
      "          bias=None,\n",
      "          in_channels=160,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=96,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=97,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=960,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding='VALID',\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=960,\n",
      "          key=u32[2],\n",
      "          kernel=f32[1,960,1,1],\n",
      "          bias=f32[960]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=98,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=99,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[320,960,1,1],\n",
      "          bias=None,\n",
      "          in_channels=960,\n",
      "          out_channels=320,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[32],\n",
      "          bias=f32[32],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=100,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=101,\n",
      "            init=<object object at 0x7f386c3e3cf0>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=32,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    Conv2d(\n",
      "      num_spatial_dims=2,\n",
      "      weight=f32[1280,320,1,1],\n",
      "      bias=None,\n",
      "      in_channels=320,\n",
      "      out_channels=1280,\n",
      "      kernel_size=(1, 1),\n",
      "      stride=(1, 1),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      use_bias=False,\n",
      "      padding_mode='ZEROS'\n",
      "    ),\n",
      "    BatchNorm(\n",
      "      weight=f32[32],\n",
      "      bias=f32[32],\n",
      "      first_time_index=StateIndex(\n",
      "        marker=102,\n",
      "        init=<object object at 0x7f386c3e3cf0>\n",
      "      ),\n",
      "      state_index=StateIndex(marker=103, init=<object object at 0x7f386c3e3cf0>),\n",
      "      axis_name='batch',\n",
      "      inference=False,\n",
      "      input_size=32,\n",
      "      eps=0.001,\n",
      "      channelwise_affine=True,\n",
      "      momentum=0.999\n",
      "    ),\n",
      "    <wrapped function relu6>,\n",
      "    AvgPool2d(\n",
      "      init=0,\n",
      "      operation=<function add>,\n",
      "      num_spatial_dims=2,\n",
      "      kernel_size=(7, 7),\n",
      "      stride=(1, 1),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      use_ceil=False\n",
      "    ),\n",
      "    Linear(\n",
      "      weight=f32[10,1280],\n",
      "      bias=f32[10],\n",
      "      in_features=1280,\n",
      "      out_features=10,\n",
      "      use_bias=True\n",
      "    ),\n",
      "    <function softmax>\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, state = eqx.nn.make_with_state(MobileNetV2_K)(in_channels=1, num_classes=10, key=key, BATCH_SIZE=BATCH_SIZE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "select cases must have the same shapes, got [(32,), (1,)].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, state, opt_state\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Example loss\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_value\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# scalar loss\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Example inference\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(model, state, x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\n\u001b[1;32m      4\u001b[0m     model: MobileNetV2_K,  state: eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mState, x: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch 1 28 28\u001b[39m\u001b[38;5;124m\"\u001b[39m], y: Int[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     batch_model \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[1;32m      7\u001b[0m         model, axis_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0m     pred_y, state \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_entropy(y, pred_y)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 256\u001b[0m, in \u001b[0;36mMobileNetV2_K.__call__\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(layer), eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mStatefulLayer) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, InvertedResidualBlock):\n\u001b[0;32m--> 256\u001b[0m         x, state \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "Cell \u001b[0;32mIn[4], line 112\u001b[0m, in \u001b[0;36mInvertedResidualBlock.__call__\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[lc:]):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(layer), eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mStatefulLayer):\n\u001b[0;32m--> 112\u001b[0m         x, state \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/CS_597/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CS_597/lib/python3.12/site-packages/equinox/nn/_batch_norm.py:164\u001b[0m, in \u001b[0;36mBatchNorm.__call__\u001b[0;34m(self, x, state, key, inference)\u001b[0m\n\u001b[1;32m    162\u001b[0m running_mean \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m momentum) \u001b[38;5;241m*\u001b[39m batch_mean \u001b[38;5;241m+\u001b[39m momentum \u001b[38;5;241m*\u001b[39m running_mean\n\u001b[1;32m    163\u001b[0m running_var \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m momentum) \u001b[38;5;241m*\u001b[39m batch_var \u001b[38;5;241m+\u001b[39m momentum \u001b[38;5;241m*\u001b[39m running_var\n\u001b[0;32m--> 164\u001b[0m running_mean \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m running_var \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mselect(first_time, batch_var, running_var)\n\u001b[1;32m    166\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_index, (running_mean, running_var))\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CS_597/lib/python3.12/site-packages/jax/_src/lax/lax.py:3825\u001b[0m, in \u001b[0;36m_select_shape_rule\u001b[0;34m(which, *cases)\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(case\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m cases[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m cases[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m   3824\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect cases must have the same shapes, got [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3825\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cases])))\n\u001b[1;32m   3826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m which\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m which\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m cases[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m   3827\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect `which` must be scalar or have the same shape as cases, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3828\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot `which` shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m but case shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: select cases must have the same shapes, got [(32,), (1,)]."
     ]
    }
   ],
   "source": [
    "# for MobileNetV2_K\n",
    "\n",
    "def loss(\n",
    "    model: MobileNetV2_K,  state: eqx.nn.State, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    batch_model = jax.vmap(\n",
    "        model, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "    )\n",
    "    pred_y, state = batch_model(x, state)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, state, opt_state, xs, ys):\n",
    "    grads, state = eqx.filter_grad(loss, has_aux=True)(model, state, xs, ys)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, state, opt_state\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(model, state, dummy_x, dummy_y)\n",
    "print(loss_value.shape)  # scalar loss\n",
    "# Example inference\n",
    "output = jax.vmap(model)(dummy_x, state)\n",
    "print(output.shape)  # batch of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(in_channels=1, num_classes=10, key=key)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MobileNetV2\n",
    "\n",
    "def loss(\n",
    "    model: MobileNetV2, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
    "    # a single input input image of shape (1, 28, 28).\n",
    "    #\n",
    "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
    "    # leading (batch) axis.\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(model, dummy_x, dummy_y)\n",
    "print(loss_value.shape)  # scalar loss\n",
    "# Example inference\n",
    "output = jax.vmap(model)(dummy_x)\n",
    "print(output.shape)  # batch of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
