{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax Implementation of MobileNetV2\n",
    "The following is a jax and equinox implementation of the MobileNetV2 architecture\n",
    "\n",
    "The implementation is broken up into its individual (modulo stride) layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Tuple, Optional, Union, Sequence\n",
    "from jaxtyping import Array, Float, Int, PyTree\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "import equinox as eqx\n",
    "\n",
    "import optax as opt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2\n",
    "\n",
    "The following is the full implementation of the MobileNetV2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Depthwise Separable Convolution Layer\n",
    "class DepthwiseSeparableConv(eqx.Module):\n",
    "    depthwise: eqx.nn.Conv2d\n",
    "    pointwise: eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, key):\n",
    "        dw_key, pw_key = jax.random.split(key)\n",
    "        self.depthwise = eqx.nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=in_channels, \n",
    "            kernel_size=(3, 3), \n",
    "            stride=stride, \n",
    "            padding=1, \n",
    "            groups=in_channels,\n",
    "            key=dw_key\n",
    "        )\n",
    "        self.pointwise = eqx.nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=(3, 3), \n",
    "            key=pw_key\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [reference](https://github.com/DarshanDeshpande/jax-models/blob/main/jax_models/layers/depthwise_separable_conv.py)\n",
    "class DepthwiseConv2D(eqx.Module):\n",
    "    in_channels: int = eqx.field(static=True)\n",
    "    out_channels: int = eqx.field(static=True)\n",
    "    kernel_size: Union[int, Sequence[int]] = eqx.field(static=True)\n",
    "    stride: Union[int, Sequence[int]] = eqx.field(static=True)\n",
    "    padding: Union[int, Sequence[int]] = eqx.field(static=True)\n",
    "    depth_multiplier: int = eqx.field(static=True)\n",
    "    use_bias: bool = eqx.field(static=True)\n",
    "    groups: int = eqx.field(static=True)\n",
    "    key: Any = eqx.field(static=True)\n",
    "\n",
    "    kernel: Array\n",
    "    bias: Array\n",
    "\n",
    "    def __init__(self, in_channels: int, depth_multiplier: int, kernel_size: Tuple[int, int], stride: Tuple[int, int], padding: Tuple[int, int], use_bias: bool, key: jr.PRNGKey):\n",
    "        self.in_channels = in_channels\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.out_channels = in_channels * depth_multiplier\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.use_bias = False\n",
    "        self.groups = in_channels\n",
    "        self.key = key\n",
    "\n",
    "        self.kernel = jr.normal(\n",
    "            key,\n",
    "            shape=(self.depth_multiplier * self.in_channels, 1) + self.kernel_size)\n",
    "\n",
    "        if use_bias:\n",
    "            self.bias = jr.normal(key, shape=(in_channels * depth_multiplier,))\n",
    "            self.use_bias = True\n",
    "        else:\n",
    "            self.bias = jnp.zeros((in_channels * depth_multiplier,))\n",
    "\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = x.reshape((x.shape[0], 1, *x.shape[1:]))\n",
    "        x = jax.lax.conv_general_dilated(\n",
    "            x,\n",
    "            self.kernel,\n",
    "            self.stride,\n",
    "            'VALID',\n",
    "            (1,) * len(self.kernel_size),\n",
    "            (1,) * len(self.kernel_size),\n",
    "            (\"NCHW\", \"OIHW\", \"NCHW\"),\n",
    "            x.shape[-1]\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an inverted residual block [reference](https://github.com/keras-team/keras/blob/v3.3.3/keras/src/applications/mobilenet_v2.py#L398)\n",
    "class InvertedResidualBlock(eqx.Module):\n",
    "    # static fields get ignored durign training\n",
    "    in_channels:  int   = eqx.field(static=True)\n",
    "    expansion:    int   = eqx.field(static=True)\n",
    "    stride:       int   = eqx.field(static=True)\n",
    "    alpha:        float = eqx.field(static=True)\n",
    "    filters:      int   = eqx.field(static=True)\n",
    "    pw_filters:   int   = eqx.field(static=True)\n",
    "    block_id:     int   = eqx.field(static=True)\n",
    "\n",
    "    layers: List[Any]\n",
    "    \n",
    "\n",
    "    def _make_divisible(self, v, divisor, min_value=None):\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "    def __init__(self, in_channels: int, expansion: int, stride: int, alpha: float, filters: int, block_id: int, key: jr.PRNGKey, BATCH_SIZE: int):\n",
    "        self.in_channels = in_channels\n",
    "        self.expansion = expansion\n",
    "        self.stride = stride\n",
    "        self.alpha = alpha\n",
    "        self.filters = filters\n",
    "        self.block_id = block_id\n",
    "\n",
    "        pointwise_filters = int(filters * alpha)\n",
    "        # ensure that the number of filters on the last 1x1 convolution is a multiple of 8\n",
    "        pointwise_filters = self._make_divisible(pointwise_filters, 8)\n",
    "        self.pw_filters = pointwise_filters\n",
    "\n",
    "        # Define the key for the block\n",
    "        key, conv_key = jr.split(key)\n",
    "        self.layers = []\n",
    "\n",
    "        # Define the layers of the block\n",
    "        if block_id:\n",
    "            # Expand with a pointwise 1x1 convolution\n",
    "            self.layers.extend([\n",
    "                eqx.nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=in_channels * expansion,\n",
    "                    kernel_size=(1, 1),\n",
    "                    use_bias=False,\n",
    "                    key=conv_key\n",
    "                ),\n",
    "                eqx.nn.BatchNorm(\n",
    "                    BATCH_SIZE,\n",
    "                    axis_name='batch',\n",
    "                    eps=1e-3,\n",
    "                    momentum=0.99\n",
    "                ),\n",
    "                jax.nn.relu6\n",
    "            ])\n",
    "        \n",
    "        self.layers.extend([\n",
    "            DepthwiseConv2D(\n",
    "                in_channels=in_channels * expansion,\n",
    "                depth_multiplier=1,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(stride, stride),\n",
    "                padding=(1, 1),\n",
    "                key=conv_key,\n",
    "                use_bias=False\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                BATCH_SIZE,\n",
    "                axis_name='batch',\n",
    "                eps=1e-3,\n",
    "                momentum=0.99\n",
    "            ),\n",
    "            jax.nn.relu6\n",
    "        ])\n",
    "\n",
    "        # pointwise 1x1 conv\n",
    "        self.layers.extend([\n",
    "            eqx.nn.Conv2d(\n",
    "                in_channels=in_channels * expansion,\n",
    "                out_channels=pointwise_filters,\n",
    "                kernel_size=(1, 1),\n",
    "                use_bias=False,\n",
    "                key=conv_key\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                BATCH_SIZE,\n",
    "                axis_name='batch',\n",
    "                eps=1e-3,\n",
    "                momentum=0.99\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        input = x\n",
    "\n",
    "        lc = 0\n",
    "        \n",
    "        if self.block_id:\n",
    "            x = self.layers[0](x)\n",
    "            x = self.layers[1](x)\n",
    "            x = self.layers[2](x)\n",
    "            lc = 3\n",
    "        if self.stride == 2:\n",
    "            x = jnp.pad(x, 1, mode='constant', constant_values=0)\n",
    "\n",
    "        for i in range(lc, len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "\n",
    "        if self.in_channels == self.pw_filters and self.stride == 1:\n",
    "            x = x + input\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Bottleneck Block\n",
    "class Bottleneck(eqx.Module):\n",
    "    _stride: int = eqx.field(static=True)\n",
    "\n",
    "    conv1: eqx.nn.Conv2d\n",
    "    depthwise_conv: DepthwiseSeparableConv\n",
    "    conv3: eqx.nn.Conv2d\n",
    "    use_residual: bool\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio, use_residual, key: jr.PRNGKey):\n",
    "        self._stride=stride\n",
    "        keys = jr.split(key, 3)\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.conv1 = eqx.nn.Conv2d(in_channels, hidden_dim, kernel_size=(1, 1), key=keys[0])\n",
    "        self.depthwise_conv = [DepthwiseSeparableConv(hidden_dim, hidden_dim, stride=1, key=keys[1]),\n",
    "                               DepthwiseSeparableConv(hidden_dim, hidden_dim, stride=2, key=keys[1])]\n",
    "        self.conv3 = eqx.nn.Conv2d(hidden_dim, out_channels, kernel_size=(1, 1), key=keys[2])\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "    def __call__(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        if self._stride == 1:\n",
    "            x = self.depthwise_conv[0](x)\n",
    "            x = jax.nn.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            return x + residual\n",
    "        else:\n",
    "            x = self.depthwise_conv[1](x)\n",
    "            x = jax.nn.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MobileNetV2\n",
    "class MobileNetV2(eqx.Module):\n",
    "    in_channels: int = eqx.field(static=True)\n",
    "    \n",
    "    first_conv: eqx.nn.Conv2d\n",
    "    bottlenecks: list\n",
    "    last_conv: eqx.nn.Conv2d\n",
    "    pool: eqx.nn.AvgPool2d\n",
    "    classifier: eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self, in_channels, num_classes, key):\n",
    "        keys = jax.random.split(key, 10)\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.first_conv = eqx.nn.Conv2d(in_channels, 32, kernel_size=(3, 3), stride=2, padding=1, key=keys[0])\n",
    "\n",
    "        # Bottleneck blocks configuration\n",
    "        bottleneck_configs = [\n",
    "            # (in_channels, out_channels, stride, expand_ratio, n_repeats)\n",
    "            (32, 16, 1, 1, 1),   # First block, no expansion, no repetition\n",
    "            (16, 24, 2, 6, 2),   # Second block, 2x stride, 2 repetitions\n",
    "            (24, 32, 2, 6, 3),   # Third block, 2x stride, 3 repetitions\n",
    "            (32, 64, 2, 6, 4),   # Fourth block, 2x stride, 4 repetitions\n",
    "            (64, 96, 1, 6, 3),   # Fifth block, stride 1, 3 repetitions\n",
    "            (96, 160, 2, 6, 3),  # Sixth block, 2x stride, 3 repetitions\n",
    "            (160, 320, 1, 6, 1), # Seventh block, stride 1, no repetition\n",
    "        ]\n",
    "\n",
    "        self.bottlenecks = []\n",
    "        current_key = keys[1]\n",
    "\n",
    "        for config in bottleneck_configs:\n",
    "            in_channels, out_channels, stride, expand_ratio, n_repeats = config\n",
    "\n",
    "            # Add the first block in the stage with the specified stride\n",
    "            self.bottlenecks.append(\n",
    "                Bottleneck(in_channels, out_channels, stride, expand_ratio, use_residual=(stride == 1), key=current_key)\n",
    "            )\n",
    "            current_key = jax.random.split(current_key, 1)[0]\n",
    "\n",
    "            # Add the remaining blocks with stride = 1\n",
    "            for i in range(n_repeats - 1):\n",
    "                self.bottlenecks.append(\n",
    "                    Bottleneck(out_channels, out_channels, stride=1, expand_ratio=expand_ratio, use_residual=True, key=current_key)\n",
    "                )\n",
    "                current_key = jax.random.split(current_key, 1)[0]\n",
    "\n",
    "        self.last_conv = eqx.nn.Conv2d(24, 1280, kernel_size=(1, 1), key=keys[2])\n",
    "        self.pool = eqx.nn.AvgPool2d(kernel_size=(7, 7))\n",
    "        self.classifier = eqx.nn.Conv2d(1280, num_classes, kernel_size=(1,1),key=keys[3])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = jax.nn.relu(x)\n",
    "\n",
    "        for bottleneck in self.bottlenecks:\n",
    "            x = bottleneck(x)\n",
    "\n",
    "        x = self.last_conv(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = jnp.mean(x, axis=(1, 2))  # Global average pooling\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 model based on the Keras implementation\n",
    "class MobileNetV2_K(eqx.Module):\n",
    "    layers: List[Any]\n",
    "\n",
    "    def _make_divisible(self, v, divisor, min_value=None):\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "    def __init__(self,\n",
    "        in_channels: int = 3,\n",
    "        alpha: float = 1.0,\n",
    "        include_top: bool = True,\n",
    "        num_classes: int = 1000,\n",
    "        classifier_activation: str = 'softmax',\n",
    "        pooling: Optional[str] = None,\n",
    "        key: jr.PRNGKey = jr.PRNGKey(0),\n",
    "        BATCH_SIZE: int = 32\n",
    "    ):\n",
    "        key, conv_key = jr.split(key)\n",
    "        \n",
    "        first_block_filters = self._make_divisible(32 * alpha, 8)\n",
    "        if alpha > 1.0:\n",
    "            last_block_filters = self._make_divisible(1280 * alpha, 8)\n",
    "        else:\n",
    "            last_block_filters = 1280\n",
    "\n",
    "        self.layers = [\n",
    "            eqx.nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=first_block_filters,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(2, 2),\n",
    "                use_bias=False,\n",
    "                key=conv_key\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                input_size=first_block_filters,\n",
    "                eps=1e-3,\n",
    "                momentum=0.99,\n",
    "                axis_name=\"batch\"\n",
    "            ),\n",
    "            jax.nn.relu6,\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=first_block_filters,\n",
    "                expansion=1,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=16,\n",
    "                block_id=0,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=16,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=24,\n",
    "                block_id=1,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=24,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=24,\n",
    "                block_id=2,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=24,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=32,\n",
    "                block_id=3,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=32,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=32,\n",
    "                block_id=4,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=32,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=32,\n",
    "                block_id=5,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=32,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=6,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=7,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=8,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=64,\n",
    "                block_id=9,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=64,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=96,\n",
    "                block_id=10,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=96,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=96,\n",
    "                block_id=11,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=96,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=96,\n",
    "                block_id=12,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=96,\n",
    "                expansion=6,\n",
    "                stride=2,\n",
    "                alpha=alpha,\n",
    "                filters=160,\n",
    "                block_id=13,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=160,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=160,\n",
    "                block_id=14,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=160,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=160,\n",
    "                block_id=15,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            InvertedResidualBlock(\n",
    "                in_channels=160,\n",
    "                expansion=6,\n",
    "                stride=1,\n",
    "                alpha=alpha,\n",
    "                filters=320,\n",
    "                block_id=16,\n",
    "                key=key,\n",
    "                BATCH_SIZE=BATCH_SIZE\n",
    "            ),\n",
    "            eqx.nn.Conv2d(\n",
    "                in_channels=320,\n",
    "                out_channels=last_block_filters,\n",
    "                kernel_size=(1, 1),\n",
    "                use_bias=False,\n",
    "                key=conv_key\n",
    "            ),\n",
    "            eqx.nn.BatchNorm(\n",
    "                input_size=BATCH_SIZE,\n",
    "                eps=1e-3,\n",
    "                momentum=0.999,\n",
    "                axis_name=\"batch\"\n",
    "            ),\n",
    "            jax.nn.relu6\n",
    "        ]\n",
    "\n",
    "        if include_top:\n",
    "            self.layers.extend([\n",
    "                eqx.nn.AvgPool2d(kernel_size=(7, 7)), # TODO: replace with global average pooling\n",
    "                eqx.nn.Linear(\n",
    "                    in_features=last_block_filters,\n",
    "                    out_features=num_classes,\n",
    "                    key=key\n",
    "                )\n",
    "            ])\n",
    "            if classifier_activation == 'softmax':\n",
    "                self.layers.append(jax.nn.softmax)\n",
    "\n",
    "        else:\n",
    "            if pooling == 'avg':\n",
    "                self.layers.append(eqx.nn.AvgPool2d(kernel_size=(7, 7))) # TODO: replace with global average pooling\n",
    "            elif pooling == 'max':\n",
    "                self.layers.append(eqx.nn.MaxPool2d(kernel_size=(7, 7))) # TODO: replace with global max pooling\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        for layer in self.layers:\n",
    "            if issubclass(type(layer), eqx.nn.StatefulLayer):\n",
    "                x, state = layer(x, state)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 300\n",
    "BATCH_SIZE = 64\n",
    "PRINT_EVERY = 30\n",
    "SEED = 42\n",
    "\n",
    "# Key generation\n",
    "key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test with MNIST\n",
    "\n",
    "# Load the MNIST dataset [reference](https://docs.kidger.site/equinox/examples/mnist/#the-dataset)\n",
    "normalise_data = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "# we aren't using a validation set here, but that's easy enough to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 28, 28)\n",
      "(64,)\n",
      "[2 1 1 3 5 4 9 8 6 8 6 5 5 4 2 0 3 0 0 6 1 9 0 2 2 7 3 2 8 5 7 8 6 2 2 1 8\n",
      " 4 1 2 0 8 3 0 3 8 4 9 1 8 0 0 3 6 3 6 5 6 3 6 9 5 7 3]\n"
     ]
    }
   ],
   "source": [
    "# Checking our data a bit (by now, everyone knows what the MNIST dataset looks like)\n",
    "dummy_x, dummy_y = next(iter(trainloader))\n",
    "dummy_x = dummy_x.numpy()\n",
    "dummy_y = dummy_y.numpy()\n",
    "print(dummy_x.shape)  # 64x1x28x28\n",
    "print(dummy_y.shape)  # 64\n",
    "print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2_K(\n",
      "  layers=[\n",
      "    Conv2d(\n",
      "      num_spatial_dims=2,\n",
      "      weight=f32[32,1,3,3],\n",
      "      bias=None,\n",
      "      in_channels=1,\n",
      "      out_channels=32,\n",
      "      kernel_size=(3, 3),\n",
      "      stride=(2, 2),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      use_bias=False,\n",
      "      padding_mode='ZEROS'\n",
      "    ),\n",
      "    BatchNorm(\n",
      "      weight=f32[32],\n",
      "      bias=f32[32],\n",
      "      first_time_index=StateIndex(\n",
      "        marker=0,\n",
      "        init=<object object at 0x7efcb8193c10>\n",
      "      ),\n",
      "      state_index=StateIndex(marker=1, init=<object object at 0x7efcb8193c10>),\n",
      "      axis_name='batch',\n",
      "      inference=False,\n",
      "      input_size=32,\n",
      "      eps=0.001,\n",
      "      channelwise_affine=True,\n",
      "      momentum=0.99\n",
      "    ),\n",
      "    <wrapped function relu6>,\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=1,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=16,\n",
      "      pw_filters=16,\n",
      "      block_id=0,\n",
      "      layers=[\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=32,\n",
      "          out_channels=32,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=32,\n",
      "          key=u32[2],\n",
      "          kernel=f32[32,1,3,3],\n",
      "          bias=f32[32]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=2,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=3,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[16,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=16,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=4,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=5,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=16,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=24,\n",
      "      pw_filters=24,\n",
      "      block_id=1,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,16,1,1],\n",
      "          bias=None,\n",
      "          in_channels=16,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=6,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=7,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=96,\n",
      "          out_channels=96,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=96,\n",
      "          key=u32[2],\n",
      "          kernel=f32[96,1,3,3],\n",
      "          bias=f32[96]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=8,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=9,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[24,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=24,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=10,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=11,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=24,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=24,\n",
      "      pw_filters=24,\n",
      "      block_id=2,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[144,24,1,1],\n",
      "          bias=None,\n",
      "          in_channels=24,\n",
      "          out_channels=144,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=12,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=13,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=144,\n",
      "          out_channels=144,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=144,\n",
      "          key=u32[2],\n",
      "          kernel=f32[144,1,3,3],\n",
      "          bias=f32[144]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=14,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=15,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[24,144,1,1],\n",
      "          bias=None,\n",
      "          in_channels=144,\n",
      "          out_channels=24,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=16,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=17,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=24,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=32,\n",
      "      pw_filters=32,\n",
      "      block_id=3,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[144,24,1,1],\n",
      "          bias=None,\n",
      "          in_channels=24,\n",
      "          out_channels=144,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=18,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=19,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=144,\n",
      "          out_channels=144,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=144,\n",
      "          key=u32[2],\n",
      "          kernel=f32[144,1,3,3],\n",
      "          bias=f32[144]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=20,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=21,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[32,144,1,1],\n",
      "          bias=None,\n",
      "          in_channels=144,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=22,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=23,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=32,\n",
      "      pw_filters=32,\n",
      "      block_id=4,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[192,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=24,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=25,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=192,\n",
      "          out_channels=192,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=192,\n",
      "          key=u32[2],\n",
      "          kernel=f32[192,1,3,3],\n",
      "          bias=f32[192]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=26,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=27,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[32,192,1,1],\n",
      "          bias=None,\n",
      "          in_channels=192,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=28,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=29,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=32,\n",
      "      pw_filters=32,\n",
      "      block_id=5,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[192,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=30,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=31,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=192,\n",
      "          out_channels=192,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=192,\n",
      "          key=u32[2],\n",
      "          kernel=f32[192,1,3,3],\n",
      "          bias=f32[192]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=32,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=33,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[32,192,1,1],\n",
      "          bias=None,\n",
      "          in_channels=192,\n",
      "          out_channels=32,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=34,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=35,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=32,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=6,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[192,32,1,1],\n",
      "          bias=None,\n",
      "          in_channels=32,\n",
      "          out_channels=192,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=36,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=37,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=192,\n",
      "          out_channels=192,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=192,\n",
      "          key=u32[2],\n",
      "          kernel=f32[192,1,3,3],\n",
      "          bias=f32[192]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=38,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=39,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,192,1,1],\n",
      "          bias=None,\n",
      "          in_channels=192,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=40,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=41,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=7,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=42,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=43,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[384,1,3,3],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=44,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=45,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=46,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=47,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=8,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=48,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=49,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[384,1,3,3],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=50,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=51,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=52,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=53,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=64,\n",
      "      pw_filters=64,\n",
      "      block_id=9,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=54,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=55,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[384,1,3,3],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=56,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=57,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[64,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=64,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=58,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=59,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=64,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=96,\n",
      "      pw_filters=96,\n",
      "      block_id=10,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[384,64,1,1],\n",
      "          bias=None,\n",
      "          in_channels=64,\n",
      "          out_channels=384,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=60,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=61,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=384,\n",
      "          out_channels=384,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=384,\n",
      "          key=u32[2],\n",
      "          kernel=f32[384,1,3,3],\n",
      "          bias=f32[384]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=62,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=63,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,384,1,1],\n",
      "          bias=None,\n",
      "          in_channels=384,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=64,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=65,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=96,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=96,\n",
      "      pw_filters=96,\n",
      "      block_id=11,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[576,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=66,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=67,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=576,\n",
      "          out_channels=576,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=576,\n",
      "          key=u32[2],\n",
      "          kernel=f32[576,1,3,3],\n",
      "          bias=f32[576]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=68,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=69,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,576,1,1],\n",
      "          bias=None,\n",
      "          in_channels=576,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=70,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=71,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=96,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=96,\n",
      "      pw_filters=96,\n",
      "      block_id=12,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[576,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=72,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=73,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=576,\n",
      "          out_channels=576,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=576,\n",
      "          key=u32[2],\n",
      "          kernel=f32[576,1,3,3],\n",
      "          bias=f32[576]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=74,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=75,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[96,576,1,1],\n",
      "          bias=None,\n",
      "          in_channels=576,\n",
      "          out_channels=96,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=76,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=77,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=96,\n",
      "      expansion=6,\n",
      "      stride=2,\n",
      "      alpha=1.0,\n",
      "      filters=160,\n",
      "      pw_filters=160,\n",
      "      block_id=13,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[576,96,1,1],\n",
      "          bias=None,\n",
      "          in_channels=96,\n",
      "          out_channels=576,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=78,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=79,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=576,\n",
      "          out_channels=576,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=576,\n",
      "          key=u32[2],\n",
      "          kernel=f32[576,1,3,3],\n",
      "          bias=f32[576]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=80,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=81,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[160,576,1,1],\n",
      "          bias=None,\n",
      "          in_channels=576,\n",
      "          out_channels=160,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=82,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=83,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=160,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=160,\n",
      "      pw_filters=160,\n",
      "      block_id=14,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[960,160,1,1],\n",
      "          bias=None,\n",
      "          in_channels=160,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=84,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=85,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=960,\n",
      "          out_channels=960,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=960,\n",
      "          key=u32[2],\n",
      "          kernel=f32[960,1,3,3],\n",
      "          bias=f32[960]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=86,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=87,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[160,960,1,1],\n",
      "          bias=None,\n",
      "          in_channels=960,\n",
      "          out_channels=160,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=88,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=89,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=160,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=160,\n",
      "      pw_filters=160,\n",
      "      block_id=15,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[960,160,1,1],\n",
      "          bias=None,\n",
      "          in_channels=160,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=90,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=91,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=960,\n",
      "          out_channels=960,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=960,\n",
      "          key=u32[2],\n",
      "          kernel=f32[960,1,3,3],\n",
      "          bias=f32[960]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=92,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=93,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[160,960,1,1],\n",
      "          bias=None,\n",
      "          in_channels=960,\n",
      "          out_channels=160,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=94,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=95,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    InvertedResidualBlock(\n",
      "      in_channels=160,\n",
      "      expansion=6,\n",
      "      stride=1,\n",
      "      alpha=1.0,\n",
      "      filters=320,\n",
      "      pw_filters=320,\n",
      "      block_id=16,\n",
      "      layers=[\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[960,160,1,1],\n",
      "          bias=None,\n",
      "          in_channels=160,\n",
      "          out_channels=960,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=96,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=97,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        DepthwiseConv2D(\n",
      "          in_channels=960,\n",
      "          out_channels=960,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          depth_multiplier=1,\n",
      "          use_bias=False,\n",
      "          groups=960,\n",
      "          key=u32[2],\n",
      "          kernel=f32[960,1,3,3],\n",
      "          bias=f32[960]\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=98,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=99,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        ),\n",
      "        <wrapped function relu6>,\n",
      "        Conv2d(\n",
      "          num_spatial_dims=2,\n",
      "          weight=f32[320,960,1,1],\n",
      "          bias=None,\n",
      "          in_channels=960,\n",
      "          out_channels=320,\n",
      "          kernel_size=(1, 1),\n",
      "          stride=(1, 1),\n",
      "          padding=((0, 0), (0, 0)),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          use_bias=False,\n",
      "          padding_mode='ZEROS'\n",
      "        ),\n",
      "        BatchNorm(\n",
      "          weight=f32[64],\n",
      "          bias=f32[64],\n",
      "          first_time_index=StateIndex(\n",
      "            marker=100,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          state_index=StateIndex(\n",
      "            marker=101,\n",
      "            init=<object object at 0x7efcb8193c10>\n",
      "          ),\n",
      "          axis_name='batch',\n",
      "          inference=False,\n",
      "          input_size=64,\n",
      "          eps=0.001,\n",
      "          channelwise_affine=True,\n",
      "          momentum=0.99\n",
      "        )\n",
      "      ]\n",
      "    ),\n",
      "    Conv2d(\n",
      "      num_spatial_dims=2,\n",
      "      weight=f32[1280,320,1,1],\n",
      "      bias=None,\n",
      "      in_channels=320,\n",
      "      out_channels=1280,\n",
      "      kernel_size=(1, 1),\n",
      "      stride=(1, 1),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      use_bias=False,\n",
      "      padding_mode='ZEROS'\n",
      "    ),\n",
      "    BatchNorm(\n",
      "      weight=f32[64],\n",
      "      bias=f32[64],\n",
      "      first_time_index=StateIndex(\n",
      "        marker=102,\n",
      "        init=<object object at 0x7efcb8193c10>\n",
      "      ),\n",
      "      state_index=StateIndex(marker=103, init=<object object at 0x7efcb8193c10>),\n",
      "      axis_name='batch',\n",
      "      inference=False,\n",
      "      input_size=64,\n",
      "      eps=0.001,\n",
      "      channelwise_affine=True,\n",
      "      momentum=0.999\n",
      "    ),\n",
      "    <wrapped function relu6>,\n",
      "    AvgPool2d(\n",
      "      init=0,\n",
      "      operation=<function add>,\n",
      "      num_spatial_dims=2,\n",
      "      kernel_size=(7, 7),\n",
      "      stride=(1, 1),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      use_ceil=False\n",
      "    ),\n",
      "    Linear(\n",
      "      weight=f32[10,1280],\n",
      "      bias=f32[10],\n",
      "      in_features=1280,\n",
      "      out_features=10,\n",
      "      use_bias=True\n",
      "    ),\n",
      "    <function softmax>\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, state = eqx.nn.make_with_state(MobileNetV2_K)(in_channels=1, num_classes=10, key=key, BATCH_SIZE=BATCH_SIZE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "conv_general_dilated feature_group_count must divide lhs feature dimension size, but 13 does not divide 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, state, opt_state\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Example loss\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_value\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# scalar loss\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Example inference\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[101], line 9\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(model, state, x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\n\u001b[1;32m      4\u001b[0m     model: MobileNetV2_K,  state: eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mState, x: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch 1 28 28\u001b[39m\u001b[38;5;124m\"\u001b[39m], y: Int[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     batch_model \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[1;32m      7\u001b[0m         model, axis_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0m     pred_y, state \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_entropy(y, pred_y)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[95], line 257\u001b[0m, in \u001b[0;36mMobileNetV2_K.__call__\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m    255\u001b[0m         x, state \u001b[38;5;241m=\u001b[39m layer(x, state)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, state\n",
      "Cell \u001b[0;32mIn[92], line 111\u001b[0m, in \u001b[0;36mInvertedResidualBlock.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m     x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mpad(x, \u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lc, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[0;32m--> 111\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpw_filters \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    114\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n",
      "Cell \u001b[0;32mIn[91], line 40\u001b[0m, in \u001b[0;36mDepthwiseConv2D.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[0;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_general_dilated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVALID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNCHW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOIHW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNCHW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m     51\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "    \u001b[0;31m[... skipping hidden 28 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/epitaxy/lib/python3.12/site-packages/jax/_src/lax/convolution.py:369\u001b[0m, in \u001b[0;36m_conv_general_dilated_shape_rule\u001b[0;34m(lhs, rhs, window_strides, padding, lhs_dilation, rhs_dilation, dimension_numbers, feature_group_count, batch_group_count, **unused_kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rem:\n\u001b[1;32m    367\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_general_dilated feature_group_count must divide lhs feature \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension size, but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not divide \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(feature_group_count, lhs_feature_count))\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal(quot, rhs\u001b[38;5;241m.\u001b[39mshape[dimension_numbers\u001b[38;5;241m.\u001b[39mrhs_spec[\u001b[38;5;241m1\u001b[39m]]):\n\u001b[1;32m    371\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv_general_dilated lhs feature dimension size divided by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_group_count must equal the rhs input feature dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize, but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m // \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: conv_general_dilated feature_group_count must divide lhs feature dimension size, but 13 does not divide 1."
     ]
    }
   ],
   "source": [
    "# for MobileNetV2_K\n",
    "\n",
    "def loss(\n",
    "    model: MobileNetV2_K,  state: eqx.nn.State, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    batch_model = jax.vmap(\n",
    "        model, axis_name=\"batch\", in_axes=(0, None), out_axes=(0, None)\n",
    "    )\n",
    "    pred_y, state = batch_model(x, state)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, state, opt_state, xs, ys):\n",
    "    grads, state = eqx.filter_grad(loss, has_aux=True)(model, state, xs, ys)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, state, opt_state\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(model, state, dummy_x, dummy_y)\n",
    "print(loss_value.shape)  # scalar loss\n",
    "# Example inference\n",
    "output = jax.vmap(model)(dummy_x, state)\n",
    "print(output.shape)  # batch of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(in_channels=1, num_classes=10, key=key)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MobileNetV2\n",
    "\n",
    "def loss(\n",
    "    model: MobileNetV2, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
    "    # a single input input image of shape (1, 28, 28).\n",
    "    #\n",
    "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
    "    # leading (batch) axis.\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(model, dummy_x, dummy_y)\n",
    "print(loss_value.shape)  # scalar loss\n",
    "# Example inference\n",
    "output = jax.vmap(model)(dummy_x)\n",
    "print(output.shape)  # batch of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
